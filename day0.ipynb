{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to determine the SeasonStage\n",
    "def determine_season_stage(date, round_info):\n",
    "    if \"Apertura\" in round_info and \"Regular Season\" in round_info:\n",
    "        return \"Apertura\"\n",
    "    elif \"Clausura\" in round_info and \"Regular Season\" in round_info:\n",
    "        return \"Clausura\"\n",
    "    elif \"Guardianes\" in round_info:\n",
    "        return \"Guardianes\"\n",
    "    else:\n",
    "        return \"Liguilla\"\n",
    "\n",
    "# Define a function to extract the year\n",
    "def extract_year(round_info, date):\n",
    "    if \"Quarter-finals\" in round_info or \"Semi-finals\" in round_info or \"Repechaje\" or \"Reclasificacion\" in round_info or \"Finals\" in round_info:\n",
    "        year = pd.to_datetime(date).year\n",
    "        year = str(year)\n",
    "        return year\n",
    "    return ''.join(filter(str.isdigit, round_info))\n",
    "\n",
    "# Define a function to determine the Season Type\n",
    "def determine_season_type(round_info):\n",
    "    if len(round_info.split('— ')) > 1:\n",
    "        return round_info.split('— ')[-1]\n",
    "    if len(round_info.split(' ')) > 1:\n",
    "        return round_info.split(' ')[-2] + \" \" + round_info.split(' ')[-1]\n",
    "    return round_info.split(' ')[-1]\n",
    "\n",
    "# Función para extraer la temporada del enlace\n",
    "def extraer_temporada(link):\n",
    "    temporada = link.split('/')[-2]\n",
    "    return temporada\n",
    "\n",
    "def fbref_pull_and_store_data(metadata):\n",
    "    # Procesar cada fila y actualizar/crear bases de datos SQL\n",
    "    # complete this ditionary with the metadata of the tables you want to update\n",
    "    unique_teams  = metadata.MetaEquipo.unique().tolist()\n",
    "    datos_equipo = []  # Inicializar el DataFrame para los datos del equipo\n",
    "    data_dict = {x : metadata[metadata.MetaEquipo == x] for x in unique_teams}\n",
    "\n",
    "    for _, grupo in data_dict.items():\n",
    "        print(f\"Procesando base de datos: \")\n",
    "\n",
    "        for _, fila in grupo.iterrows():\n",
    "            tabla_nombre = fila['Tabla']\n",
    "            link = fila['Link']\n",
    "            metaequipo = fila['MetaEquipo']\n",
    "            temporada = extraer_temporada(link) \n",
    "\n",
    "            print(f\"Descargando datos de {tabla_nombre}, {metaequipo}.{temporada} desde {link}\")\n",
    "            \n",
    "            time.sleep(3)  # Espera 1 segundo entre cada solicitud\n",
    "            datos_tabla = pd.read_html(link)\n",
    "            datos_tabla = datos_tabla[1]\n",
    "            datos_tabla['Temporada'] = temporada  # Agregar la temporada como columna\n",
    "            datos_tabla['MetaEquipo'] = metaequipo\n",
    "            \n",
    "            datos_tabla.columns = datos_tabla.columns.str.replace(' ', '_') # Reemplazar espacios con guiones bajos \n",
    "            # datos_tabla.columns = datos_tabla.columns.droplevel(0)\n",
    "            datos_equipo.append(datos_tabla)\n",
    "    return pd.concat(datos_equipo, ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando base de datos: \n",
      "Descargando datos de scores_and_fixtures, Barcelona-2023-2024 desde https://fbref.com/en/squads/206d90db/2023-2024/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2022-2023 desde https://fbref.com/en/squads/206d90db/2022-2023/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2021-2022 desde https://fbref.com/en/squads/206d90db/2021-2022/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2020-2021 desde https://fbref.com/en/squads/206d90db/2020-2021/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2019-2020 desde https://fbref.com/en/squads/206d90db/2019-2020/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2018-2019 desde https://fbref.com/en/squads/206d90db/2018-2019/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2017-2018 desde https://fbref.com/en/squads/206d90db/2017-2018/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2016-2017 desde https://fbref.com/en/squads/206d90db/2016-2017/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2015-2016 desde https://fbref.com/en/squads/206d90db/2015-2016/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2014-2015 desde https://fbref.com/en/squads/206d90db/2014-2015/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2013-2014 desde https://fbref.com/en/squads/206d90db/2013-2014/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2012-2013 desde https://fbref.com/en/squads/206d90db/2012-2013/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2011-2012 desde https://fbref.com/en/squads/206d90db/2011-2012/Barcelona-Stats#all_matchlogs\n",
      "Descargando datos de scores_and_fixtures, Barcelona-2010-2011 desde https://fbref.com/en/squads/206d90db/2010-2011/Barcelona-Stats#all_matchlogs\n",
      "Procesando base de datos: \n",
      "Descargando datos de scores_and_fixtures, Alaves-2023-2024 desde https://fbref.com/en/squads/8d6fd021/2023-2024/Alaves-Stats#all_matchlogs\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metadata \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/csvdata/metadata.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m retrieved_data \u001b[39m=\u001b[39m fbref_pull_and_store_data(metadata)\n",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m, in \u001b[0;36mfbref_pull_and_store_data\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDescargando datos de \u001b[39m\u001b[39m{\u001b[39;00mtabla_nombre\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mmetaequipo\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mtemporada\u001b[39m}\u001b[39;00m\u001b[39m desde \u001b[39m\u001b[39m{\u001b[39;00mlink\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# Espera 1 segundo entre cada solicitud\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m datos_tabla \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(link)\n\u001b[1;32m     53\u001b[0m datos_tabla \u001b[39m=\u001b[39m datos_tabla[\u001b[39m1\u001b[39m]\n\u001b[1;32m     54\u001b[0m datos_tabla[\u001b[39m'\u001b[39m\u001b[39mTemporada\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m temporada  \u001b[39m# Agregar la temporada como columna\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1207\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1208\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1209\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1222\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[1;32m    987\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[1;32m    988\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs)\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/html.py:821\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 821\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    822\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(r, \u001b[39m\"\u001b[39m\u001b[39mtext_content\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/html.py:802\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     \u001b[39mif\u001b[39;00m is_url(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio):\n\u001b[0;32m--> 802\u001b[0m         \u001b[39mwith\u001b[39;00m urlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mio) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    803\u001b[0m             r \u001b[39m=\u001b[39m parse(f, parser\u001b[39m=\u001b[39mparser)\n\u001b[1;32m    804\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m         \u001b[39m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/broodds/lib/python3.9/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"data/csvdata/metadata.csv\")\n",
    "\n",
    "retrieved_data = fbref_pull_and_store_data(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broodds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6224cace7a2c3a8b1d006e8222cc1fd11dcfdd694065c7276e6d8f1f530588c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
